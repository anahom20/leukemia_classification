{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxEbf-CocE9T",
        "outputId": "4d268f66-c9ec-4d2b-96de-c3274d9b2560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVsSh0YTrcsk",
        "outputId": "99f2155b-d337-4522-b86c-e004f1c2dc08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-y41n_pgm\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/CLIP.git > /dev/null #run only once / runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhQQ7mNrluj7"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile as zf, BadZipFile\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/Samples.zip\"\n",
        "\n",
        "try:\n",
        "    with zf(file_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(\"/\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at path: {file_path}\")\n",
        "except BadZipFile:\n",
        "    print(f\"Error: Invalid or corrupted zip file at path: {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC9VNIEASkUT",
        "outputId": "b72f18bb-510b-41ff-8b75-0c6c2d2fe183"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                         precision    recall  f1-score   support\n",
            "\n",
            "                 Benign       0.81      0.17      0.29        75\n",
            "      [Malignant] Pre-B       0.82      0.80      0.81       138\n",
            "      [Malignant] Pro-B       0.42      0.51      0.46        97\n",
            "[Malignant] early Pre-B       0.46      0.59      0.52       144\n",
            "\n",
            "               accuracy                           0.57       454\n",
            "              macro avg       0.63      0.52      0.52       454\n",
            "           weighted avg       0.62      0.57      0.56       454\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#SVM\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/TestData/data - Train.csv')\n",
        "\n",
        "df = df.drop(columns=[\"Image\"])\n",
        "\n",
        "X = df.drop(columns=[\"Actual\"])\n",
        "y = df[\"Actual\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "svm_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svm', SVC(kernel='rbf'))\n",
        "])\n",
        "\n",
        "svm_pipeline.fit(X_train, y_train)\n",
        "\n",
        "joblib.dump(svm_pipeline, '/content/svm_model.pkl')\n",
        "\n",
        "loaded_model = joblib.load('/content/svm_model.pkl')\n",
        "\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5UMaUDS-bfe",
        "outputId": "c2463e82-cbbf-4f33-c4ee-cf26ff9581fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actual\n",
            "3    685\n",
            "1    668\n",
            "2    557\n",
            "0    357\n",
            "Name: count, dtype: int64\n",
            "['Benign' '[Malignant] Pre-B' '[Malignant] Pro-B'\n",
            " '[Malignant] early Pre-B']\n"
          ]
        }
      ],
      "source": [
        "#TO OBTAIN THE LABEL ENCODER AS VLM OPERATES W NUMBERS\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/TestData/data - Train.csv\")\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"Actual\"] = label_encoder.fit_transform(df[\"Actual\"])\n",
        "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
        "\n",
        "\n",
        "# Optionally print to check\n",
        "print(df[\"Actual\"].value_counts())\n",
        "print(label_encoder.classes_)  # Shows which class maps to which number\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6A31lFrmbYzL"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class BloodSmearDataset(Dataset):\n",
        "    def __init__(self, dataframe, image_transform=None):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.transform = image_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.loc[idx]\n",
        "        image = Image.open(row[\"Image\"]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        tabular_features = torch.tensor([\n",
        "            row[\"Count\"], row[\"Mean\"], row[\"Max\"], row[\"Std\"]\n",
        "        ], dtype=torch.float)\n",
        "        label = torch.tensor(row[\"Actual\"], dtype=torch.long)\n",
        "        return image, tabular_features, label\n",
        "\n",
        "class VLMClassifier(nn.Module):\n",
        "    def __init__(self, image_feature_dim=512, tabular_dim=4, hidden_dim=128, num_classes=4):\n",
        "        super().__init__()\n",
        "        self.tabular_net = nn.Sequential(\n",
        "            nn.Linear(tabular_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(image_feature_dim + hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, image_features, tabular_features):\n",
        "        tabular_out = self.tabular_net(tabular_features)\n",
        "        combined = torch.cat([image_features, tabular_out], dim=1)\n",
        "        return self.classifier(combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTpqCISYmU3X",
        "outputId": "3c01004d-56c3-4bd1-9526-6b0ce194cb0d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338M/338M [00:03<00:00, 108MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: ðŸŸ¢ Saved best model. Train Loss = 1.1526, Val Loss = 1.0073\n",
            "Epoch 2: ðŸŸ¢ Saved best model. Train Loss = 0.9149, Val Loss = 0.8087\n",
            "Epoch 3: ðŸŸ¢ Saved best model. Train Loss = 0.7404, Val Loss = 0.6590\n",
            "Epoch 4: ðŸŸ¢ Saved best model. Train Loss = 0.6081, Val Loss = 0.5475\n",
            "Epoch 5: ðŸŸ¢ Saved best model. Train Loss = 0.5053, Val Loss = 0.4623\n",
            "Epoch 6: ðŸŸ¢ Saved best model. Train Loss = 0.4340, Val Loss = 0.4041\n",
            "Epoch 7: ðŸŸ¢ Saved best model. Train Loss = 0.3776, Val Loss = 0.3556\n",
            "Epoch 8: ðŸŸ¢ Saved best model. Train Loss = 0.3370, Val Loss = 0.3176\n",
            "Epoch 9: ðŸŸ¢ Saved best model. Train Loss = 0.3010, Val Loss = 0.2852\n",
            "Epoch 10: ðŸŸ¢ Saved best model. Train Loss = 0.2720, Val Loss = 0.2675\n",
            "Epoch 11: ðŸŸ¢ Saved best model. Train Loss = 0.2504, Val Loss = 0.2393\n",
            "Epoch 12: ðŸŸ¢ Saved best model. Train Loss = 0.2297, Val Loss = 0.2232\n",
            "Epoch 13: ðŸŸ¢ Saved best model. Train Loss = 0.2108, Val Loss = 0.2042\n",
            "Epoch 14: ðŸŸ¢ Saved best model. Train Loss = 0.1979, Val Loss = 0.1924\n",
            "Epoch 15: ðŸŸ¢ Saved best model. Train Loss = 0.1806, Val Loss = 0.1768\n",
            "Epoch 16: ðŸŸ¢ Saved best model. Train Loss = 0.1679, Val Loss = 0.1718\n",
            "Epoch 17: ðŸŸ¢ Saved best model. Train Loss = 0.1591, Val Loss = 0.1536\n",
            "Epoch 18: ðŸŸ¢ Saved best model. Train Loss = 0.1475, Val Loss = 0.1475\n",
            "Epoch 19: ðŸŸ¢ Saved best model. Train Loss = 0.1407, Val Loss = 0.1405\n",
            "Epoch 20: Train Loss = 0.1347, Val Loss = 0.1437\n",
            "Epoch 21: ðŸŸ¢ Saved best model. Train Loss = 0.1250, Val Loss = 0.1221\n",
            "Epoch 22: ðŸŸ¢ Saved best model. Train Loss = 0.1176, Val Loss = 0.1151\n",
            "Epoch 23: ðŸŸ¢ Saved best model. Train Loss = 0.1117, Val Loss = 0.1105\n",
            "Epoch 24: ðŸŸ¢ Saved best model. Train Loss = 0.1069, Val Loss = 0.1049\n",
            "Epoch 25: ðŸŸ¢ Saved best model. Train Loss = 0.1024, Val Loss = 0.1000\n"
          ]
        }
      ],
      "source": [
        "#WITH VALIDATION\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import pandas as pd\n",
        "import clip\n",
        "\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/TestData/data - Train.csv\")\n",
        "val_df = pd.read_csv(\"/content/drive/MyDrive/TestData/data - Val.csv\")\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_df[\"Actual\"] = label_encoder.fit_transform(train_df[\"Actual\"])\n",
        "val_df[\"Actual\"] = label_encoder.transform(val_df[\"Actual\"])\n",
        "\n",
        "joblib.dump(label_encoder, \"/content/drive/MyDrive/label_encoder.pkl\")\n",
        "\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073),\n",
        "                         (0.26862954, 0.26130258, 0.27577711))\n",
        "])\n",
        "\n",
        "train_dataset = BloodSmearDataset(train_df, image_transform)\n",
        "val_dataset = BloodSmearDataset(val_df, image_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
        "clip_model.eval()\n",
        "\n",
        "vlm_model = VLMClassifier(num_classes=len(label_encoder.classes_)).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(vlm_model.parameters(), lr=1e-4)\n",
        "\n",
        "num_epochs = 30\n",
        "best_val_loss = float(\"inf\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    vlm_model.train()\n",
        "    total_loss = 0.0\n",
        "    for images, tabular_data, labels in train_loader:\n",
        "        with torch.no_grad():\n",
        "            image_features = clip_model.encode_image(images.to(device)).float()\n",
        "        outputs = vlm_model(image_features, tabular_data.to(device))\n",
        "        loss = criterion(outputs, labels.to(device))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "    vlm_model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, tabular_data, labels in val_loader:\n",
        "            image_features = clip_model.encode_image(images.to(device)).float()\n",
        "            outputs = vlm_model(image_features, tabular_data.to(device))\n",
        "            loss = criterion(outputs, labels.to(device))\n",
        "            val_loss += loss.item()\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        torch.save(vlm_model.state_dict(), \"/content/best_vlm_model.pth\")\n",
        "        print(f\"Epoch {epoch+1}: ðŸŸ¢ Saved best model. Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n",
        "    else:\n",
        "        print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gW99S5zupojY"
      },
      "outputs": [],
      "source": [
        "#WITHOUT VALIDATION\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import pandas as pd\n",
        "import clip\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/TestData/data - Train.csv\")\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"Actual\"] = label_encoder.fit_transform(df[\"Actual\"])\n",
        "\n",
        "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"Actual\"])\n",
        "\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073),\n",
        "                         (0.26862954, 0.26130258, 0.27577711))\n",
        "])\n",
        "\n",
        "train_dataset = BloodSmearDataset(train_df, image_transform)\n",
        "test_dataset = BloodSmearDataset(test_df, image_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
        "clip_model.eval()\n",
        "\n",
        "vlm_model = VLMClassifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(vlm_model.parameters(), lr=1e-4)\n",
        "\n",
        "# Training loop with saving\n",
        "num_epochs = 30\n",
        "best_loss = float(\"inf\")\n",
        "for epoch in range(num_epochs):\n",
        "    vlm_model.train()\n",
        "    total_loss = 0.0\n",
        "    for images, tabular_data, labels in train_loader:\n",
        "        with torch.no_grad():\n",
        "            image_features = clip_model.encode_image(images.to(device)).float()\n",
        "        outputs = vlm_model(image_features, tabular_data.to(device))\n",
        "        loss = criterion(outputs, labels.to(device))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        torch.save(vlm_model.state_dict(), \"/content/best_vlm_model.pth\")\n",
        "        print(f\"Epoch {epoch+1}: ðŸŸ¢ Saved best model. Loss = {avg_loss:.4f}\")\n",
        "    else:\n",
        "        print(f\"Epoch {epoch+1}: Loss = {avg_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSbBwLNAoHIK"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/best_vlm_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO4EHPADD3s2",
        "outputId": "28ef54f7-b4e7-464b-a97b-5e55afdbb940"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338M/338M [00:03<00:00, 98.5MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                         precision    recall  f1-score   support\n",
            "\n",
            "                 Benign       0.97      0.95      0.96        78\n",
            "      [Malignant] Pre-B       0.99      0.99      0.99       144\n",
            "      [Malignant] Pro-B       0.99      0.99      0.99       120\n",
            "[Malignant] early Pre-B       0.98      0.99      0.98       148\n",
            "\n",
            "               accuracy                           0.98       490\n",
            "              macro avg       0.98      0.98      0.98       490\n",
            "           weighted avg       0.98      0.98      0.98       490\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import clip\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "\n",
        "\n",
        "image_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.48145466, 0.4578275, 0.40821073),\n",
        "                             (0.26862954, 0.26130258, 0.27577711))\n",
        "    ])\n",
        "\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/TestData/data - Test.csv\")\n",
        "label_encoder = joblib.load(\"/content/drive/MyDrive/label_encoder.pkl\")\n",
        "\n",
        "test_df[\"Actual\"] = label_encoder.transform(test_df[\"Actual\"])\n",
        "test_dataset = BloodSmearDataset(test_df, image_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
        "clip_model.eval()\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "vlm_model = VLMClassifier().to(device)\n",
        "vlm_model.load_state_dict(torch.load(\"/content/drive/MyDrive/best_vlm_model.pth\"))\n",
        "vlm_model.eval()\n",
        "\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, tabular_data, labels in test_loader:\n",
        "        image_features = clip_model.encode_image(images.to(device)).float()\n",
        "        outputs = vlm_model(image_features, tabular_data.to(device))\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Convert to actual class names\n",
        "all_pred_names = label_encoder.inverse_transform(all_preds)\n",
        "all_label_names = label_encoder.inverse_transform(all_labels)\n",
        "\n",
        "print(classification_report(all_label_names, all_pred_names))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
